{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to invoke modularized python code from src\n",
    "This notebook acts as a convenient entry point for running all functions defined in the 'src' folder, eliminating the need to execute any of the .py files. By importing the necessary modules directly into the notebook, the functions can be quickly and easily accessed and run with defined input parameters. Their output can be examined and used as inputs for other functions. With this the ML training, evaluation or inference flow can be easily run using the already refactored code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# import relevant libraries\n",
    "from xgb_churn_prediction.data import data_ingestion, data_clean, data_split, data_output\n",
    "from xgb_churn_prediction.model import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables needed to run functions\n",
    "param_1 = \"test\"\n",
    "param_2 = \"test\"\n",
    "project = \"\"\n",
    "label = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run data_ingestion functions\n",
    "query = data_ingestion.create_data_query(param_1, param_2)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_ingestion.execute_bq_query(project, query)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run data_clean functions\n",
    "df_cleaned = data_clean.clean_data(df)\n",
    "df_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run data_split functions\n",
    "train_test_split = data_split.split_data(df_cleaned)\n",
    "train_df = train_test_split.train_data\n",
    "test_df = train_test_split.test_data\n",
    "train_df.head(10), test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train into X, y values\n",
    "train_X, train_y = data_split.split_X_y(train_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run train functions\n",
    "model = train.train(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluation functions\n",
    "evaluation = evaluate.evaluate_model(test_df, model)\n",
    "print(evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales-forecasting-delivery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
