{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tracking\n",
    "\n",
    "This notebook provides a place to run model experiments and log these experiments to the Vertex AI Experiment Tracker.  \n",
    "\n",
    "Through Vertex AI Experiments, this notebook will:\n",
    "1. track the steps of an experiment run (e.g. data ingestion, preprocessing, training)\n",
    "2. track the inputs to a model (e.g. parameters, datasets)\n",
    "3. track the outputs from a model run (e.g. models themselves, model metrics, processed datasets)\n",
    "\n",
    "[Documentation for the Vertex AI SDK](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.ExperimentRun) that we will be using.  \n",
    "[Documentation around experiment tracking](https://cloud.google.com/vertex-ai/docs/experiments/intro-vertex-ai-experiments) for more background information.\n",
    "____________________________________________________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to Use this Notebook\n",
    "\n",
    "**Throughout the notebook, each `TODO` comment indicates steps that need to be updated**\n",
    "\n",
    "1. Declare the constants in the first two blocks\n",
    "2. Update the model training cells under the 'Perform Model Training' block\n",
    "3. Run the notebook end to end (run all cells)\n",
    "4. Check the outcome in the Vertex Experiments UI\n",
    "    - navigate to the 'Vertex AI' dashboard\n",
    "    - under the 'Model Development' tab on the left hand side, click on 'Experiments'\n",
    "    - the experiment, with the name set below, will be shown here\n",
    "\n",
    "____________________________________________________________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcomes of running the notebook\n",
    "\n",
    "1. Create a new experiment, if one isn't already created\n",
    "    - using the same experiment name across notebook runs will append new experiment runs to the same experiment\n",
    "2. Create a new run under the experiment name defined in the cell below \n",
    "3. Logging 3 artifacts to the experiment run\n",
    "    - log custom defined parameters (defined in the `PARAMETERS` dictionary)\n",
    "    - log custom defined metrics (defined in the `METRICS` dictionary)\n",
    "    - log/upload the trained model to GCS\n",
    "\n",
    "_____________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Declare Experiment Constants\n",
    "\n",
    "Let's set the constants needed for creating an experiment.\n",
    "\n",
    "The first box will need to be **updated just once**, at the beginning of each experiment. These are experiment level constants.\n",
    "\n",
    "The second box will need to be **updated multiple times**, with an update for each run of the notebook/experiment. These are run level constants, which will impact runs inside an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update these variables when first initiating an experiment\n",
    "\n",
    "# the name of the experiment that will be used to track our metrics\n",
    "EXPERIMENT_NAME='forecasting-experiment'\n",
    "# description of the experiment above\n",
    "EXPERIMENT_DESCRIPTION='experimenting with model types for forecasting'\n",
    "# our GCP project ID \n",
    "PROJECT_ID=\"\"\n",
    "# the region of our gcp project\n",
    "LOCATION=\"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update these variables with each run of an experiment\n",
    "import time\n",
    "\n",
    "# the name of this run of the experiment\n",
    "RUN_NAME='run-{}'.format(int(time.time()))\n",
    "# the name of our model\n",
    "MODEL_NAME = \"example-model-1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create our experiment\n",
    "\n",
    "Now that the constants used for our experiment are recorded above, the experiment can be created. There is no code that needs to be updated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Create an experiment in our project with the given name & description\n",
    "def create_experiment_run_sample() -> aiplatform.ExperimentRun:\n",
    "    # initialise our experiment here using the constants we declared above\n",
    "    aiplatform.init(\n",
    "        experiment=EXPERIMENT_NAME,\n",
    "        experiment_description=EXPERIMENT_DESCRIPTION,\n",
    "        project=PROJECT_ID,\n",
    "        location=LOCATION,\n",
    "    )\n",
    "\n",
    "    # within our experiment, start a new run for this session\n",
    "    my_run = aiplatform.start_run(run=RUN_NAME)\n",
    "    return my_run\n",
    "\n",
    "gcp_run = create_experiment_run_sample()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform model training\n",
    "\n",
    "Steps for model training:\n",
    "1. Import relevant libraries\n",
    "2. Declare relevant parameters\n",
    "3. Import training data\n",
    "4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import the relevant libraries here\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare our parameters used for training\n",
    "\n",
    "For each run of this experiment:\n",
    "1. Declare parameters for the current run\n",
    "2. Define a dictionary of these parameters for logging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: declare model parameters here\n",
    "\n",
    "# model parameters\n",
    "MODEL_TYPE='ARIMA_PLUS'\n",
    "TIMESTAMP_COL = 'receipt_date'\n",
    "SERIES_ID_COL = 'store_id'\n",
    "HOLIDAY_REGION = 'NZ'\n",
    "MODEL_REGISTRY='vertex_ai'\n",
    "\n",
    "# data parameters\n",
    "TRAINING_DATA_MIN_DATE = '2017-01-01'\n",
    "TRAINING_DATA_MAX_DATE = '2022-04-04'\n",
    "# the percentage of data to be used as training data\n",
    "TRAIN_SPLIT = 0.8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PARAMETERS` dictionary is created for logging purposes. This dictionary will later be logged to our experiment run, with all of the parameters we've defined. This dictionary can have any arbitrary `[key,value]` pair to be logged.\n",
    "\n",
    "For example, a custom parameter which is not used otherwise can be added as shown below. This is useful when you want to log information to the experiment run.\n",
    "```\n",
    "PARAMETERS = {\n",
    "    'model_type': \"XG BOOST\", \n",
    "    'stores_used': \"Only the top 50 stores\",\n",
    "    'notes': \"Running the same hyperparameters as before\",\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update this dictionary with parameters used\n",
    "PARAMETERS = {\n",
    "    'model_type': MODEL_TYPE, \n",
    "    'timestamp_col': TIMESTAMP_COL, \n",
    "    'series_id_col': SERIES_ID_COL,\n",
    "    'holiday_region': HOLIDAY_REGION,\n",
    "    'model_registry': MODEL_REGISTRY,\n",
    "    'training_date_min_date': TRAINING_DATA_MIN_DATE,\n",
    "    'training_date_max_date': TRAINING_DATA_MAX_DATE,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import training data\n",
    "\n",
    "These cells may or may not need updating for each run of the experiment. Steps include:\n",
    "\n",
    "1. Helper function to execute queries in BigQuery\n",
    "2. Defining the SQL query that fetches our training data\n",
    "3. Executing the above two functions and generate training/validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the client and function for executing a sql statement on BigQuery\n",
    "\n",
    "def execute_bq_sql(bq_sql: str) -> pd.DataFrame:\n",
    "    bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "    query_job = bq_client.query(bq_sql)\n",
    "    return query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import training data - the below query is an example query\n",
    "\n",
    "def get_train_data() -> str:\n",
    "    train_data_sql = f'''SELECT\n",
    "       * from training_data\n",
    "    '''\n",
    "    return train_data_sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from Bigquery\n",
    "training_sql = get_train_data()\n",
    "query_result = execute_bq_sql(training_sql)\n",
    "# Generate splits\n",
    "train=query_result.sample(frac=TRAIN_SPLIT,random_state=5)\n",
    "test=query_result.drop(train.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train our model\n",
    "\n",
    "This cell is for training a custom python model with the data we fetched above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# TODO: perform custom training here & update types\n",
    "def train_model(train: pd.DataFrame) -> SVC:\n",
    "    model = SVC()\n",
    "\n",
    "    return model\n",
    "\n",
    "model_artifact = train_model(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model & generate metrics\n",
    "\n",
    "In this cell, we will extract metrics from our trained model. This requires\n",
    "1. Generating metrics using the trained model & the test dataset\n",
    "2. Defining a metrics dictionary that maps the metrics we want to capture to the values of these metrics for this run of the experiment\n",
    "\n",
    "Note, third party packages are often used to generate these metrics. For example:\n",
    "\n",
    "```\n",
    "import sklearn\n",
    "y_true = test_data['target_column']\n",
    "y_pred = trained_model.predict(train_data)\n",
    "mse = sklearn.metrics.mean_squared_error(y_true, y_pred, squared=True)\n",
    "```\n",
    "\n",
    "________________\n",
    "\n",
    "This dictionary is similar to the `PARAMETERS` dictionary, where any `[key,value]` pairs can be added for logging purposes. The user running the notebook needs to decide which metrics are most relevant to log to the experiment run.\n",
    "\n",
    "Alternative `METRICS` example:\n",
    "```\n",
    "METRICS = {'r2_score': .45479, 'MSE': 2342245, 'rmse': 2523, 'quartile': \"Tenth\"}\n",
    "```\n",
    "_______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: perform model evaluation here\n",
    "METRICS = {'mse': .9, 'recall': .86}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Log the outputs of the run\n",
    "\n",
    "After having trained a model, log the parameters used & training metrics from the model run.\n",
    "\n",
    "Specifically, we are interestred in capturing:\n",
    "1. data we are using for each run of a model\n",
    "2. model artefacts (the trained model itself)\n",
    "3. metrics of model performance\n",
    "4. hyperparameters we used to train this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: log additional info, outside of what is already captured here (e.g. custom artifacts)\n",
    "def log_run(my_run: aiplatform.ExperimentRun, model_artifact: \"ExperimentModel\") -> None:\n",
    "    \"\"\"\n",
    "    Log the results of the experiment using all of the output recorded above.\n",
    "    \"\"\"\n",
    "    my_run.log_params(PARAMETERS)\n",
    "    my_run.log_metrics(METRICS)\n",
    "    my_run.log_model(\n",
    "        model=model_artifact,\n",
    "        uri=\"artifacts-bucket/models/\" + MODEL_NAME + \"/\" + RUN_NAME, \n",
    "        display_name=MODEL_NAME,\n",
    "    )\n",
    "\n",
    "log_run(gcp_run, model_artifact)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. End our experiment run\n",
    "\n",
    "We have now created a run of an experiment and logged the key metrics & parameters to our centralised experiment tracking workspace.\n",
    "\n",
    "Running the following cell will end the run of the experiment, and change the status of the experiment run to completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end the run of this experiment\n",
    "gcp_run.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4d9c66101f1e8806242ee70aad36880110f21ea0508c7d8c97263028a7f9213"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
